## 问题列表

- ### 梯度爆炸的解决办法
    

- ### MLP 的万能近似定理

    一个前馈神经网络如果具有至少一个非线性输出层，那么只要给予网络足够数量的隐藏单元，它就可以以任意的精度来近似任何从一个有限维空间到另一个有限维空间的函数。

    > 《Deep Learning》 ch6.4.1 - 万能近似性质和深度

- ### 在 MLP 中，深度与宽度的关系，及其表示能力的差异
    
    隐藏层的数量称为模型的**深度**，隐藏层的维数（单元数）称为该层的**宽度**。
    
    **万能近似定理**表明一个单层的网络就足以表达任意函数，但是该层的维数可能非常大，且几乎没有泛化能力；此时，使用更深的模型能够减少所需的单元数，同时增强泛化能力（减少泛化误差）。参数数量相同的情况下，浅层网络比深层网络更容易过拟合。

    > 《Deep Learning》 ch6.4 - 架构设计；这一节的内容比较分散，想要更好的回答这个问题，需要理解深度学习的本质——学习多层次组合（ch1.2），这才是现代深度学习的基本原理。




